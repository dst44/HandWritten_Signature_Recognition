{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "DATADIR = \"H:/Datasets/Signatures\"\n",
    "CATEGORIES = [\"Genuine\" , \"Forgery\"]\n",
    "\n",
    "''' performing some initial checks to see everything is working\n",
    "for category in CATEGORIES\n",
    "    path = os.path.join(DATADIR, category)\n",
    "    for img in os.listdir(path)\n",
    "        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE) #convert the images into an array #then convert to grayscale\n",
    "        plt.imshow(img_array , cmap = \"gray\")\n",
    "        plt.show()\n",
    "        break\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "#we haven't yet mapped the data to a numerical value\n",
    "\n",
    "def create_training_data():\n",
    "    \n",
    "    for category in CATEGORIES\n",
    "    path = os.path.join(DATADIR, category)\n",
    "    \n",
    "    class_num = CATEGORIES.index(category) #this sets it 0 if genuine, 1 if forgery\n",
    "    \n",
    "    for img in os.listdir(path)\n",
    "        try:\n",
    "            \n",
    "            #read the image and convert to grayscale\n",
    "            img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE) \n",
    "            \n",
    "            #add salt-pepper noise to image\n",
    "            \n",
    "            Mat saltpepper_noise = Mat::zeros(img_array.rows, img_array.cols,CV_8U);\n",
    "            randu(saltpepper_noise,0,255);\n",
    "\n",
    "            Mat black = saltpepper_noise < 30;\n",
    "            Mat white = saltpepper_noise > 225;\n",
    "\n",
    "            Mat saltpepper_img = img_array.clone();\n",
    "            saltpepper_img.setTo(255,white);\n",
    "            saltpepper_img.setTo(0,black);\n",
    "            \n",
    "            #remove noise using median filter of size 9x9\n",
    "            \n",
    "            final_image = cv2.medianBlur(saltpepper_img , 9)\n",
    "           \n",
    "            #we resize all the images to 256X256\n",
    "            IMG_SIZE = 256\n",
    "            new_array = cv2.resize(final_img , (IMG_SIZE , IMG_SIZE))\n",
    "            \n",
    "            #add image into training_data array\n",
    "            training_data.append([new_array,class_num])\n",
    "        \n",
    "        except Exception as e: #this will not take in the broken images into the training data\n",
    "            pass\n",
    "        \n",
    "create_training_data();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sometimes data set is imbalanced ... like there are more forgeries than genuine\n",
    "#we have class weights that we can pass to let the model know if there is an imbalance in the input data\n",
    "#it will then weigh the loss a little differently and try to handle the data\n",
    "#this is not an ideal situation though\n",
    "#eg. if there are 75% forgery, the net will always predict dog and will be right 75% of the times\n",
    "\n",
    "#to deal with this we shuffle training data so things are randomised\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in training_data\n",
    "    print(sample[1]) #this will print the labels #just checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables we will feed into the neural net\n",
    "# X = feature set\n",
    "# Y = labels\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in training_data\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1,IMG_SIZE, IMG_SIZE, 1) \n",
    "#-1 is the no. of features we have #-1 in particular is a catch-all\n",
    "#shape of data is known to be IMG_SIZEX x IMG_SIZEY\n",
    "# 1 cuz this is grayscale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because the NN will need to be trained and tweaked repeatedly, we will save the current dataset\n",
    "#in a pickle and get it back every time using pickle.load()\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\", wb)\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\", wb)\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
